{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.loadDataset as loadDataset\n",
    "import src.build_tensors as build_tensors\n",
    "import src.select_feature_fields as select_feature_fields\n",
    "import src.build_features_from_tensors as build_features_from_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/PATH/TO/CLINICAL/DATA/FLATFILES/\"\n",
    "desc_dir = \"/PATH/TO/CLINICAL/DATA/DESCRIPTION_FILES/\"\n",
    "tensor_dir = \"../test_commpass_ia9_tensors/\"\n",
    "param_dir = \"parameters/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_test_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if run_test_data:\n",
    "    ##What files are we searching through to build features?\n",
    "    file_names = [\"stand_alone_ae\", \"per_patient_visit\", \"stand_alone_treatment_regimen\", 'stand_alone_emergency_dept', 'stand_alone_admissions', 'stand_alone_medhx', 'stand_alone_famhx', 'per_patient']\n",
    "    ##What strings invalidate a field as a feature?  Mostly correspond to meta-data or dates\n",
    "    invalid_strings = [\"date\", \"day\", \"week\", \"time\", \"enr\", \"interval\", \"dose\", \"unit\", \"frequency\", \"ongoing\", \"route\", \"_was\", \"visit\", \"censor\", \"d_pt\", \"ic_\", \"bmt\", \"flag\", \"vj\", \"mmtx_therapy\", \"mmtx_type\", \"dictionary\"]\n",
    "    ##What date are we using as the cutoff for no longer baseline?\n",
    "    baseline_cutoff = 0\n",
    "    ##What fraction of the feature's observations must be before treatment to treat it as a baseline feature?\n",
    "    temporal_frac = 0.5\n",
    "    select_feature_fields.main(file_names, invalid_strings, baseline_cutoff, temporal_frac, data_dir, param_dir, desc_dir)\n",
    "    ##Create tensor dir if it doesn't already exist\n",
    "    import os\n",
    "    if not os.path.exists(tensor_dir):\n",
    "        os.makedirs(tensor_dir)\n",
    "    ##What's the min last visit number to include a person in the cohort?\n",
    "    visit_cutoff = 1\n",
    "    ##What's the minimum date, i.e. where is time zero for the tensors?\n",
    "    min_date = -180\n",
    "    ##Should we use the minimum date or set our own min date?\n",
    "    calc_min_date = False\n",
    "    ##The minimum number of time to see a text value to count it as a feature\n",
    "    min_occurrences = 50\n",
    "    ##Set debug to True to run with only 50 people and min_occurrences set to 5\n",
    "    debug = True\n",
    "    build_tensors.process_commpass(visit_cutoff, min_date, calc_min_date, min_occurrences, data_dir, tensor_dir, param_dir, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = loadDataset.main(\"clinical\", tensor_dir)\n",
    "clinical_tensor = dataset['tensor']\n",
    "clinical_obs_tensor = dataset['obs_tensor']\n",
    "clinical_feature_names = dataset['feature_names']\n",
    "clinical_feature_types = dataset['feature_types']\n",
    "people = dataset['people']\n",
    "\n",
    "dataset = loadDataset.main(\"initial\", tensor_dir)\n",
    "initial_tensor = dataset['tensor']\n",
    "initial_feature_names = dataset['feature_names']\n",
    "initial_feature_types = dataset['feature_types']\n",
    "assert np.array_equal(dataset['people'], people)\n",
    "\n",
    "dataset = loadDataset.main(\"treatment\", tensor_dir)\n",
    "treatment_tensor = dataset['tensor']\n",
    "treatment_obs_tensor = dataset['obs_tensor']\n",
    "treatment_feature_names = dataset['feature_names']\n",
    "treatment_feature_types = dataset['feature_types']\n",
    "assert np.array_equal(dataset['people'], people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import src.util as util\n",
    "import os\n",
    "\n",
    "files = []\n",
    "for fname in os.listdir(param_dir):\n",
    "    if \".csv\" in fname:\n",
    "        files.append(fname)\n",
    "        \n",
    "dates = {}\n",
    "features = {}\n",
    "num_features = {}\n",
    "text_features = {}\n",
    "tensor_dates = {}\n",
    "tensor_features = {}\n",
    "for person in people:\n",
    "    dates[person] = []\n",
    "    features[person] = []\n",
    "    num_features[person] = []\n",
    "    text_features[person] = []\n",
    "    tensor_dates[person] = []\n",
    "    tensor_features[person] = []\n",
    "    \n",
    "for fname in files:\n",
    "    if \"_fields\" in fname:\n",
    "        date_dict = util.get_date_fields(param_dir, fname.replace(\"_fields.csv\", \"\"))\n",
    "    else:\n",
    "        print fname\n",
    "        continue\n",
    "    \n",
    "    date_fields = []\n",
    "    valid_fields = []\n",
    "    for key in date_dict:\n",
    "        date_fields.append(date_dict[key])\n",
    "        valid_fields.append(key)\n",
    "    date_fields = list(set(date_fields))\n",
    "    \n",
    "    data, fields = util.read_clinical_data(data_dir+fname.replace(\"_fields.csv\", \"\").replace(\"_baseline\", \"\").upper()+\".csv\", param_dir)\n",
    "    date_indices = []\n",
    "    valid_indices = []\n",
    "    for i, field in enumerate(fields):\n",
    "        if field in date_fields:\n",
    "            date_indices.append(i)\n",
    "        if field in valid_fields:\n",
    "            valid_indices.append(i)\n",
    "            \n",
    "    for person in people:\n",
    "        if person in data:\n",
    "            for line in data[person]:\n",
    "                for i in range(len(line)):\n",
    "                    if i in date_indices:\n",
    "                        if line[i] != \"\":\n",
    "                            dates[person].append(line[i])\n",
    "                    if i in valid_indices:\n",
    "                        if line[i] != \"\":\n",
    "                            features[person].append(line[i])                \n",
    "        \n",
    "for person in people:\n",
    "    dates[person] = list(set(dates[person]))\n",
    "    for i in range(len(dates[person])):\n",
    "        dates[person][i] = int(dates[person][i])\n",
    "    features[person] = list(set(features[person]))\n",
    "    num_features[person] = []\n",
    "    for i in range(len(features[person])):\n",
    "        try:\n",
    "            num = float(features[person][i])\n",
    "            num_features[person].append(num)\n",
    "        except:\n",
    "            text_features[person].append(features[person][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##There should be no dates in the tensors that aren't in the raw data, or are 0, or multiples of 90.\n",
    "##These get imputed for missing dates sometimes, so they're allowed.  Note, this ignores treatments since it abides\n",
    "##by different rules\n",
    "min_date = -180\n",
    "for i in range(clinical_obs_tensor.shape[0]):\n",
    "    nz_dates = list(set(np.nonzero(clinical_obs_tensor[i, :, :])[0]))\n",
    "    tensor_dates[people[i]] += nz_dates\n",
    "for i in range(initial_tensor.shape[0]):\n",
    "    nz_dates = list(set(np.nonzero(initial_tensor[i, :, :])[0]))\n",
    "    tensor_dates[people[i]] += nz_dates\n",
    "\n",
    "for person in people:\n",
    "    tensor_dates[person] = list(set(tensor_dates[person]))\n",
    "\n",
    "for person in people:\n",
    "    for date in tensor_dates[person]:\n",
    "        if date + min_date not in dates[person]:\n",
    "            assert date % 90 == 0, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Dates in the raw data but not in the tensor should be rare (although not unheard of).\n",
    "##Some features get thrown \n",
    "\n",
    "for person in people:\n",
    "    to_print = []\n",
    "    for date in dates[person]:\n",
    "         if date - min_date not in tensor_dates[person]:\n",
    "            if date - min_date >= 0:\n",
    "                to_print.append(date)\n",
    "\n",
    "    if len(to_print):\n",
    "        print person\n",
    "        for date in to_print:\n",
    "            print date\n",
    "        print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensor_features = {}\n",
    "for person in people:\n",
    "    tensor_features[person] = []\n",
    "    \n",
    "for i in range(len(people)):\n",
    "    nz_features = list(np.unique(clinical_tensor[i, :, :]))\n",
    "    tensor_features[people[i]] += nz_features\n",
    "for i in range(len(people)):\n",
    "    nz_features = list(np.unique(initial_tensor[i, :, :]))  \n",
    "    tensor_features[people[i]] += nz_features\n",
    "   \n",
    "for person in people:\n",
    "    tensor_features[person] = list(set(tensor_features[person]))\n",
    "    \n",
    "for person in people:\n",
    "    #print sorted(tensor_features[person])\n",
    "    #print sorted(num_features[person])\n",
    "    for feature in tensor_features[person]:\n",
    "        if feature != 0. and feature != 1.:\n",
    "            assert feature in num_features[person], feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Most common clinical features\"\n",
    "util.most_common_features(tensor_dir, file_type=\"clinical\", obs=False, sort=\"count\", cutoff=10, top=True)\n",
    "print \"\\n Least common clinical features\"\n",
    "util.most_common_features(tensor_dir, file_type=\"clinical\", obs=False, sort=\"count\", cutoff=10, top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Most common initial features\"\n",
    "util.most_common_features(tensor_dir, file_type=\"initial\", obs=False, sort=\"count\", cutoff=10, top=True)\n",
    "print \"\\n Least common initial features\"\n",
    "util.most_common_features(tensor_dir, file_type=\"initial\", obs=False, sort=\"count\", cutoff=10, top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Most common treatment features\"\n",
    "util.most_common_features(tensor_dir, file_type=\"treatment\", obs=False, sort=\"count\", top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}